{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IntroDL-Mnist",
      "provenance": [],
      "authorship_tag": "ABX9TyM3bHl/OWLvHxHXsDKJXGse",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/carranza96/DLSeminar/blob/master/notebooks/IntroDL_Mnist.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r7v5_aIBuJc-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3dd5a3f3-baed-4854-99d6-c73bfe9422d0"
      },
      "source": [
        "%pip install tensorflow==2.1\n",
        "import tensorflow.keras as keras\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n",
        "from tensorflow.keras import backend as K\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==2.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/d4/c0cd1057b331bc38b65478302114194bd8e1b9c2bbc06e300935c0e93d90/tensorflow-2.1.0-cp36-cp36m-manylinux2010_x86_64.whl (421.8MB)\n",
            "\u001b[K     |████████████████████████████████| 421.8MB 40kB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1) (1.0.8)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1) (1.11.2)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1) (0.2.2)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1) (0.9.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1) (1.17.5)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1) (3.10.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1) (0.8.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1) (1.1.0)\n",
            "Requirement already satisfied: scipy==1.4.1; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1) (1.4.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1) (3.1.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1) (0.1.8)\n",
            "Collecting tensorboard<2.2.0,>=2.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/23/53ffe290341cd0855d595b0a2e7485932f473798af173bbe3a584b99bb06/tensorboard-2.1.0-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 48.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1) (1.12.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1) (1.1.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1) (1.15.0)\n",
            "Collecting tensorflow-estimator<2.2.0,>=2.1.0rc0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/18/90/b77c328a1304437ab1310b463e533fa7689f4bfc41549593056d812fab8e/tensorflow_estimator-2.1.0-py2.py3-none-any.whl (448kB)\n",
            "\u001b[K     |████████████████████████████████| 450kB 66.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1) (0.34.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow==2.1) (2.8.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorflow==2.1) (45.1.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1) (0.16.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1) (0.4.1)\n",
            "Collecting google-auth<2,>=1.6.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1c/6d/7aae38a9022f982cf8167775c7fc299f203417b698c27080ce09060bba07/google_auth-1.11.0-py2.py3-none-any.whl (76kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 13.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1) (3.1.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1) (2.21.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1) (1.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1) (4.0.0)\n",
            "Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1) (4.0)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1) (2019.11.28)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1) (3.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1) (3.1.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1) (0.4.8)\n",
            "\u001b[31mERROR: tensorboard 2.1.0 has requirement grpcio>=1.24.3, but you'll have grpcio 1.15.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement google-auth~=1.4.0, but you'll have google-auth 1.11.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: google-auth, tensorboard, tensorflow-estimator, tensorflow\n",
            "  Found existing installation: google-auth 1.4.2\n",
            "    Uninstalling google-auth-1.4.2:\n",
            "      Successfully uninstalled google-auth-1.4.2\n",
            "  Found existing installation: tensorboard 1.15.0\n",
            "    Uninstalling tensorboard-1.15.0:\n",
            "      Successfully uninstalled tensorboard-1.15.0\n",
            "  Found existing installation: tensorflow-estimator 1.15.1\n",
            "    Uninstalling tensorflow-estimator-1.15.1:\n",
            "      Successfully uninstalled tensorflow-estimator-1.15.1\n",
            "  Found existing installation: tensorflow 1.15.0\n",
            "    Uninstalling tensorflow-1.15.0:\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uwUCso1grsNb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Fix random seed to allow reproducible experiments\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1bW3b0IDwprh",
        "colab_type": "text"
      },
      "source": [
        "# Load and inspect MNIST data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SUDgJmq1wWo5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KO4lBXrYwz5v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Shape X_train: \", x_train.shape)\n",
        "print(\"Shape y_train: \", y_train.shape)\n",
        "print(\"Shape X_test: \", x_test.shape)\n",
        "print(\"Shape y_test: \", y_test.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AhXc08Sl2PDh",
        "colab_type": "text"
      },
      "source": [
        "Values of one instance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rT-OGTEG2Mxr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"y:\", y_train[0])\n",
        "print(\"x:\", x_train[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LKYXkjCf17mv",
        "colab_type": "text"
      },
      "source": [
        "Visualize some examples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_3BhFfAK1Vut",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(16,8))\n",
        "for i in range(10):\n",
        "    plt.subplot(1, 10, i+1)\n",
        "    plt.imshow(x_train[i])\n",
        "    plt.text(0, 0, y_train[i], color='black', bbox=dict(facecolor='white', alpha=1))\n",
        "    plt.axis('off')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QyHpaa2w2rz4",
        "colab_type": "text"
      },
      "source": [
        "Class frequency"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vug2cKN22s4S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from collections import Counter\n",
        "Counter(y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SCDEmRw96euB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "NUM_CLASSES = 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_gabl0Pz--h",
        "colab_type": "text"
      },
      "source": [
        "# Multi-Layer Perceptron"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HRAixEkP6E4i",
        "colab_type": "text"
      },
      "source": [
        "![texto alternativo](https://miro.medium.com/proxy/1*eloYEyFrblGHVZhU345PJw.jpeg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HVOjdkmVKdvY",
        "colab_type": "text"
      },
      "source": [
        "## Data preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vPe1va6o3UaV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert matrices to vector (images are 28x28 pixels)\n",
        "X_train = x_train.reshape(60000, 784) # 28 * 28 = 784\n",
        "X_test = x_test.reshape(10000, 784)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4AaIdEBgyAil",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Normalize data\n",
        "# Transform from range [0., 255. ] to range [0., 1.]\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255\n",
        "X_test /= 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-WlA48R4Kmr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Transform y to one-hot enconding vectors\n",
        "from keras.utils import np_utils\n",
        "Y_train = keras.utils.to_categorical(y_train, NUM_CLASSES)\n",
        "Y_test = keras.utils.to_categorical(y_test, NUM_CLASSES)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l9dNarKr4ep7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Show example of one-hot enconding vector\n",
        "print(\"Class of first example:\", y_train[0])\n",
        "print(\"One-hot enconding:\")\n",
        "print(list(range(NUM_CLASSES)))\n",
        "print(Y_train[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e6vgRAvR5aAg",
        "colab_type": "text"
      },
      "source": [
        "NOTE: One-hot encoding not strictly necessary, it depends on the selected loss function.\n",
        "\n",
        "If categorical_cross_entropy -> one-hot enconding\n",
        "\n",
        "If sparse_categorical_cross_entropy -> integer class"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fk1e0G-eKgxg",
        "colab_type": "text"
      },
      "source": [
        "## Create model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JbFvkq9Ax1nN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create model with three dense layers\n",
        "model = Sequential()\n",
        "model.add(Dense(64, input_shape=(784,), activation='relu', use_bias=True)) # Input vector shape (28x28=784)\n",
        "model.add(Dense(128, activation='relu', use_bias=True)) \n",
        "model.add(Dense(NUM_CLASSES, activation='softmax')) # 10 output neurons, one associated to each digit. Softmax activation function\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.SGD(learning_rate=0.01), \n",
        "              metrics=['accuracy'])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sa_DrFWjCdnn",
        "colab_type": "text"
      },
      "source": [
        "## Train model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uYWTthYW7TRk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history = model.fit(X_train, Y_train,\n",
        "          batch_size=64,\n",
        "          epochs=20,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, Y_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cRu1VM9OCsAd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Visualize training stats \n",
        "\n",
        "plt.figure()\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.legend(['Training', 'Validation'])\n",
        "\n",
        "plt.figure()\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.legend(['Training', 'Validation'], loc='lower right')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RVu1o_7iDXqj",
        "colab_type": "text"
      },
      "source": [
        "## Evaluate model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQss9b397Rns",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "score = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PYqB1j85ECjH",
        "colab_type": "text"
      },
      "source": [
        "### Visualize predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LCOIAGNzEEwO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions = model.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lfzTLEYGEYr4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Example of predictions for first image\n",
        "# Output is vector of size 10, one value for each digit. Maximum value is the predicted digit\n",
        "predictions[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rVKWmxmqERfZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "df = pd.DataFrame(confusion_matrix(np.argmax(Y_test,axis=1), np.argmax(predictions,axis=1)), columns=list(range(10)))\n",
        "plt.figure(figsize=(16,8))\n",
        "sns.heatmap(df, annot=True, fmt='g', cmap=\"Blues\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rb_VEIwGGVIW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Visualize some wrong predictions \n",
        "integer_predictions = np.argmax(predictions,axis=1)\n",
        "integer_labels = np.argmax(Y_test,axis=1)\n",
        "wrong_predictions_indices = np.where( integer_predictions !=  integer_labels)[0]\n",
        "plt.figure(figsize=(16,8))\n",
        "for i in range(10):\n",
        "    index = wrong_predictions_indices[i]\n",
        "    plt.subplot(1, 10, i+1)\n",
        "    plt.imshow(x_train[index])\n",
        "    plt.text(0, 0, integer_predictions[i], color='black', bbox=dict(facecolor='white', alpha=1))\n",
        "    plt.axis('off')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I7X7_bKjDcuI",
        "colab_type": "text"
      },
      "source": [
        "### MLP with Dropout"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i4cz0RJ_DiBf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(64, input_shape=(784,), activation='relu', use_bias=True)) # Input vector shape (28x28=784)\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(128, activation='relu', use_bias=True)) \n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(NUM_CLASSES, activation='softmax')) # 10 output neurons, one associated to each digit. Softmax activation function\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.SGD(learning_rate=0.01), \n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(X_train, Y_train,\n",
        "          batch_size=64,\n",
        "          epochs=5,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, Y_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pO0Uk3w7FUK5",
        "colab_type": "text"
      },
      "source": [
        "### How to improve results?\n",
        "\n",
        "*   Adjust parameters in dense layers (number of neurons, activation function)\n",
        "*   Add more dense layers\n",
        "*   Dropout\n",
        "*   Change optimizer: SGD, Adam, Adagrad, RMSProp\n",
        "*   Change architecture: CNN, LSTM\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fjqz9rm7IxTx",
        "colab_type": "text"
      },
      "source": [
        "# Convolutional Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MyETV28KKWl0",
        "colab_type": "text"
      },
      "source": [
        "![texto alternativo](https://miro.medium.com/max/3744/1*SGPGG7oeSvVlV5sOSQ2iZw.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8X56XJ0mLMSq",
        "colab_type": "text"
      },
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C_jw7yajI0-D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Input shape now is 3-dimensional (num_examples, 28, 28, 1). We need to reshape to indicate number of channels\n",
        "X_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
        "X_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
        "input_shape = (28, 28, 1)\n",
        "\n",
        "# Normalization\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255\n",
        "X_test /= 255\n",
        "\n",
        "# One-hot encoding\n",
        "Y_train = keras.utils.to_categorical(y_train, 10)\n",
        "Y_test = keras.utils.to_categorical(y_test, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PomOaB7ZLOCn",
        "colab_type": "text"
      },
      "source": [
        "## Create CNN model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ME6E98q3LSp9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "# Conv2D with con 32 convolutional filters with kernel size 3x3\n",
        "model.add(Conv2D(32, (3, 3), padding='same', input_shape=(input_shape), activation='relu')) \n",
        "model.add(Flatten()) # Convert from matrices to vector before Fully Connected Layers\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=keras.optimizers.SGD(learning_rate=0.01),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Print model architecture\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UdZrD4fdqrO1",
        "colab_type": "text"
      },
      "source": [
        "## Train CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGHFKTpxL0tE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hist = model.fit(X_train, Y_train, batch_size=64, \n",
        "                 epochs=5, verbose=1, \n",
        "                 validation_data=(X_test, Y_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qIdwTc6ZMNSJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Visualize training stats \n",
        "plt.figure()\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.legend(['Training', 'Validation'])\n",
        "\n",
        "plt.figure()\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.legend(['Training', 'Validation'], loc='lower right')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DfvtkW6yL9F2",
        "colab_type": "text"
      },
      "source": [
        "## Evaluate model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RwhxJRNiL8ZX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "score = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OMr3Tm4OL-6P",
        "colab_type": "text"
      },
      "source": [
        "## Visualize predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d2A4tJKvMBZQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions = model.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "St5c0bmZMFV7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Visualize some wrong predictions \n",
        "integer_predictions = np.argmax(predictions,axis=1)\n",
        "integer_labels = np.argmax(Y_test,axis=1)\n",
        "wrong_predictions_indices = np.where( integer_predictions !=  integer_labels)[0]\n",
        "plt.figure(figsize=(16,8))\n",
        "for i in range(10):\n",
        "    index = wrong_predictions_indices[i]\n",
        "    plt.subplot(1, 10, i+1)\n",
        "    plt.imshow(x_train[index])\n",
        "    plt.text(0, 0, integer_predictions[i], color='black', bbox=dict(facecolor='white', alpha=1))\n",
        "    plt.axis('off')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cy2OhUUCo2PT",
        "colab_type": "text"
      },
      "source": [
        "## Exercise: Create CNN model with the following characteristics\n",
        "\n",
        "2 convolution+pooling blocks with increasing number of filters and relu activation function\n",
        "\n",
        "Dropout after convolution\n",
        "\n",
        "Fully connected block at the end\n",
        "\n",
        "Change optimizer (search in Keras docs for available optimizers)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3puKrzEo2pS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model = Sequential()\n",
        "\n",
        "# model.add(....)\n",
        "\n",
        "\n",
        "# model.compile(...)\n",
        "\n",
        "\n",
        "        \n",
        "#  hist = model.fit(X_train, Y_train, batch_size=64, \n",
        "#                  epochs=5, verbose=1, \n",
        "#                  validation_data=(X_test, Y_test))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}